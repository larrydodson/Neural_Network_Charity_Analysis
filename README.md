# Neural_Network_Charity_Analysis
Neural Network Model, UTMCC DataViz Module 19

---

## Contents 
  * Overview
    - Purpose
    - Resources
  * Results
  * Summary
 

---  

## Overview 
  
  In support of the Alphabet Soup Charity Foundation predict where to make the most favorable investments. 

   ### Purpose
   To apply machine learning and neural networks, and using the features within the provided dataset, create a binary classifier that is capable of predicting whether applicants will be successful if funded by Alphabet Soup Charity Foundation. 
  
   The deliverables are: 
   - Deliverable 1: Preprocessing Data for a Neural Network Model
   - Deliverable 2: Compile, Train, and Evaluate the Model
   - Deliverable 3: Optimize the Model
   - Deliverable 4: Written Report 
  
   
  
   ### Resources
  * Data source file: charity_data.csv
  * Software tools: Windows10, Jupyter Notebook, Python 3.8.3, Pandas, Scikit-learn, TensorFlow
  
<br>

--- 

## Results


### Deliverable 1: Preprocessing Data for a Neural Network Model



Questions on Data Preprocessing:
- What variable(s) are considered the target(s) for your model?

 `IS_SUCCESSFUL`

- What variable(s) are considered to be the features for your model?

 `APPLICATION_TYPE,	AFFILIATION,	CLASSIFICATION,	USE_CASE,	ORGANIZATION,	STATUS,	INCOME_AMT,	SPECIAL_CONSIDERATIONS,	ASK_AM`


- What variable(s) are neither targets nor features, and should be removed from the input data?

 `EIN,	NAME`

.

### Deliverable 2: Compile, Train, and Evaluate the Model



Questions on Compiling, Training, and Evaluating the Model:
- How many neurons, layers, and activation functions did you select for your neural network model, and why?


- Were you able to achieve the target model performance?


- What steps did you take to try and increase model performance?



.

### Deliverable 3: Optimize the Model

####Processing for Optimization of the Model: 
|  | Attempt-1<br>(original) | Attempt-2 | Attempt-3 | Attempt-4 |
|  | :--- | :---: | :---: | :---: | 
|  | 1. Noisy variables are removed from features
 2. Additional neurons are added to hidden layers
 3. Additional hidden layers are added
 4. The activation function of hidden layers  
 5. The activation function of output layer | a | b | c | d |
 | Loss:<br> Accuracy: | a | b | c | d |


 


.

### Deliverable 4: Written Report 
   (this readme.md file)


.

 
   | **abc** |
   | :---: |
   | ![]() |




<br>

---

## Summary
  (written summary)

### Recommendation 

#### Using a different model to solve the classification problem:


#### Explanation and Justification description:

.

.end

