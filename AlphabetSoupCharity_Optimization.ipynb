{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable 3: Optimize the Model (Attempts)\n",
    "###   Preprocessing the Data for a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Import and read the charity_data.csv.\n",
    "application_df = pd.read_csv(\"resources/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0                  T10       Independent          C1000    ProductDev   \n",
       "1                   T3       Independent          C2000  Preservation   \n",
       "2                   T5  CompanySponsored          C3000    ProductDev   \n",
       "3                   T3  CompanySponsored          C2000  Preservation   \n",
       "4                   T3       Independent          C1000     Heathcare   \n",
       "...                ...               ...            ...           ...   \n",
       "34294               T4       Independent          C1000    ProductDev   \n",
       "34295               T4  CompanySponsored          C3000    ProductDev   \n",
       "34296               T3  CompanySponsored          C2000  Preservation   \n",
       "34297               T5       Independent          C3000    ProductDev   \n",
       "34298               T3       Independent          C1000  Preservation   \n",
       "\n",
       "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
       "0       Association       1              0                      N      5000   \n",
       "1      Co-operative       1         1-9999                      N    108590   \n",
       "2       Association       1              0                      N      5000   \n",
       "3             Trust       1    10000-24999                      N      6692   \n",
       "4             Trust       1  100000-499999                      N    142590   \n",
       "...             ...     ...            ...                    ...       ...   \n",
       "34294   Association       1              0                      N      5000   \n",
       "34295   Association       1              0                      N      5000   \n",
       "34296   Association       1              0                      N      5000   \n",
       "34297   Association       1              0                      N      5000   \n",
       "34298  Co-operative       1          1M-5M                      N  36500179   \n",
       "\n",
       "       IS_SUCCESSFUL  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "34294              0  \n",
       "34295              0  \n",
       "34296              0  \n",
       "34297              1  \n",
       "34298              0  \n",
       "\n",
       "[34299 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df = application_df.drop(columns=['EIN','NAME'])\n",
    "application_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE          object\n",
       "AFFILIATION               object\n",
       "CLASSIFICATION            object\n",
       "USE_CASE                  object\n",
       "ORGANIZATION              object\n",
       "STATUS                     int64\n",
       "INCOME_AMT                object\n",
       "SPECIAL_CONSIDERATIONS    object\n",
       "ASK_AMT                    int64\n",
       "IS_SUCCESSFUL              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data types\n",
    "application_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE          17\n",
       "AFFILIATION                6\n",
       "CLASSIFICATION            71\n",
       "USE_CASE                   5\n",
       "ORGANIZATION               4\n",
       "INCOME_AMT                 9\n",
       "SPECIAL_CONSIDERATIONS     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_cat = application_df.dtypes[application_df.dtypes == 'object'].index.tolist()\n",
    "application_df[application_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T14        3\n",
       "T25        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "apptype_count = application_df.APPLICATION_TYPE.value_counts()\n",
    "apptype_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f2eed11640>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the value counts of APPLICATION_TYPE with a density() plot\n",
    "apptype_plt = apptype_count.plot.density()\n",
    "apptype_plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than ...?\n",
    "replace_application = list(apptype_count[apptype_count < 200].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in replace_application:\n",
    "    application_df.APPLICATION_TYPE = application_df.APPLICATION_TYPE.replace(app,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df.APPLICATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "         ...  \n",
       "C2190        1\n",
       "C2150        1\n",
       "C2500        1\n",
       "C5200        1\n",
       "C1732        1\n",
       "Name: CLASSIFICATION, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "class_count = application_df.CLASSIFICATION.value_counts()\n",
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f2ef48c0a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the value counts of CLASSIFICATION, with density()\n",
    "class_plt = class_count.plot.density()\n",
    "class_plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "Other     6062\n",
       "C1200     4837\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than ..?\n",
    "replace_class = list(class_count[class_count < 2000].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in replace_class:\n",
    "    application_df.CLASSIFICATION = application_df.CLASSIFICATION.replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns: ... \n",
    "# application_df = application_df.drop(columns=[\"CLASSIFICATION\"])\n",
    "# application_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APPLICATION_TYPE',\n",
       " 'AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable lists\n",
    "application_cat = application_df.dtypes[application_df.dtypes == \"object\"].index.tolist()\n",
    "application_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>APPLICATION_TYPE_T8</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  \\\n",
       "0                     0.0                   1.0                   0.0   \n",
       "1                     0.0                   0.0                   0.0   \n",
       "2                     0.0                   0.0                   0.0   \n",
       "3                     0.0                   0.0                   0.0   \n",
       "4                     0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  1.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  1.0   \n",
       "3                  1.0                  0.0                  0.0   \n",
       "4                  1.0                  0.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  APPLICATION_TYPE_T8  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   AFFILIATION_CompanySponsored  ...  INCOME_AMT_1-9999  \\\n",
       "0                           0.0  ...                0.0   \n",
       "1                           0.0  ...                1.0   \n",
       "2                           1.0  ...                0.0   \n",
       "3                           1.0  ...                0.0   \n",
       "4                           0.0  ...                0.0   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                     0.0                       0.0                 0.0   \n",
       "1                     0.0                       0.0                 0.0   \n",
       "2                     0.0                       0.0                 0.0   \n",
       "3                     1.0                       0.0                 0.0   \n",
       "4                     0.0                       1.0                 0.0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0               0.0                     0.0              0.0   \n",
       "1               0.0                     0.0              0.0   \n",
       "2               0.0                     0.0              0.0   \n",
       "3               0.0                     0.0              0.0   \n",
       "4               0.0                     0.0              0.0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                0.0                       1.0                       0.0  \n",
       "1                0.0                       1.0                       0.0  \n",
       "2                0.0                       1.0                       0.0  \n",
       "3                0.0                       1.0                       0.0  \n",
       "4                0.0                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(application_df[application_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(application_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                     0.0   \n",
       "1       1   108590              1                     0.0   \n",
       "2       1     5000              0                     0.0   \n",
       "3       1     6692              1                     0.0   \n",
       "4       1   142590              1                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                   1.0                   0.0                  0.0   \n",
       "1                   0.0                   0.0                  1.0   \n",
       "2                   0.0                   0.0                  0.0   \n",
       "3                   0.0                   0.0                  1.0   \n",
       "4                   0.0                   0.0                  1.0   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  0.0                  0.0                  0.0  ...   \n",
       "2                  0.0                  1.0                  0.0  ...   \n",
       "3                  0.0                  0.0                  0.0  ...   \n",
       "4                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "application_df = application_df.merge(encode_df,left_index=True, right_index=True)\n",
    "application_df = application_df.drop(application_cat,1)\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempting to reduce noisy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3.429900e+04\n",
      "mean     2.769199e+06\n",
      "std      8.713045e+07\n",
      "min      5.000000e+03\n",
      "25%      5.000000e+03\n",
      "50%      5.000000e+03\n",
      "75%      7.742000e+03\n",
      "max      8.597806e+09\n",
      "Name: ASK_AMT, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f2ef4f2d90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEECAYAAAABJn7JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARJ0lEQVR4nO3df2zcd33H8dfLZycephMpTSvAhMCoyrWXjoA1NojQDPuD7lfL2rVYhQbsKf/MnoUEHsjVWJGyrRGZ5pkfUkQ8Em26snWsDEpgGjtgnljBwcmaxuOHaCgG1hhl0GAtycV57w9fHMc48deJL/e5u+dDinz+3tdfvy1Vz371ufve1xEhAEC6Wmo9AADg8gg1ACSOUANA4gg1ACSOUANA4gg1ACSuaqG2PWb7uO0jGfZ9me0v2v4v21+y3VmtuQCg3lTzjPoTkt6Scd8PSdofEbdL+qCkP6/WUABQb6oW6oj4iqQTi7fZ/iXbn7d90Pa/235V5albJX2x8rgk6c5qzQUA9eZar1HvkTQQEa+V9B5JH61sPyzp7srjt0q6zvYLr/FsAJCk1mv1i2w/X9LrJf2D7fOb11e+vkfSh22/U9JXJP1A0tlrNRsApOyahVrzZ+8/iYhXL30iIn4o6fekhaDfHRE/vYazAUCyrtnSR0Q8J+lp278vSZ73y5XHN9g+P8v7JY1dq7kAIHXVfHteUdJXJd1ie9p2n6T7JfXZPizpKV140fDXJX3T9rck3SRpZ7XmAoB6Yz7mFADSxpWJAJC4qryYeMMNN8TmzZurcWgAaEgHDx78cURsXO65qoR68+bNmpiYqMahAaAh2f7epZ5j6QMAEkeoASBxhBoAEkeoASBxhBoAEkeo0RSKxaIKhYJyuZwKhYKKxWKtRwIyI9RoeMViUYODg5qdnZUkzc7OanBwkFijbhBqNLyhoSG1trZqbGxMp06d0tjYmFpbWzU0NFTr0YBMCDUa3vT0tPbt26fu7m61tbWpu7tb+/bt0/T0dK1HAzIh1ACQOEKNhtfZ2akHHnhApVJJ5XJZpVJJDzzwgDo7udk96gOhRsPbtWuX5ubm1Nvbq/Xr16u3t1dzc3PatWtXrUcDMiHUaHg9PT0aGRlRR0eHbKujo0MjIyPq6emp9WhAJlW5cUBXV1fw6XkAkJ3tgxHRtdxznFEDQOIINQAkjlADQOIINQAkjlADQOIyhdr2u20/ZfuI7aLt9moPBgCYt2Kobb9E0h9J6oqIgqScpLdVezAAwLysSx+tkn7Bdquk50n6YfVGAgAstmKoI+IHkj4k6RlJP5L004j4l6X72d5he8L2xMzMzNpPCgBNKsvSxwZJd0p6uaQXS+qw/fal+0XEnojoioiujRs3rv2kANCksix9/IakpyNiJiLKkj4l6fXVHQsAcF6WUD8j6VdtP8+2Jb1Z0lR1xwIAnJdljfoJSY9K+oakJys/s6fKcwEAKlqz7BQRH5D0gSrPAgBYBlcmAkDiCDUAJI5QA0DiCDUAJI5QA0DiCDUAJI5QA0DiCDUAJI5QA0DiCDUAJI5QA0DiCDUAJI5QA0DiCDUAJI5QA0DiCDUAJI5QA0DiCDUAJI5QA0DiCDUAJI5QA0DiCDUAJI5QA0DiCDUAJI5QA0DiCDUAJI5QA0DiCDUAJI5QA0DiCDUAJI5QA0DiCDUAJI5QA0DiCDUAJI5QA0DiCDUAJI5QA0DiMoXa9gtsP2r7v21P2f61ag8GAJjXmnG/EUmfj4h7bK+T9LwqzgQAWGTFUNv+RUlvlPROSYqIM5LOVHcsAMB5WZY+XiFpRtLf2J60/XHbHUt3sr3D9oTtiZmZmTUfFACaVZZQt0p6jaSPRcRWSbOS3rd0p4jYExFdEdG1cePGNR4TAJpXllBPS5qOiCcq3z+q+XADAK6BFUMdEf8j6fu2b6lserOko1WdCgCwIOu7PgYk/V3lHR/flfSu6o0EAFgsU6gj4pCkrirPAgBYBlcmoikUi0UVCgXlcjkVCgUVi8VajwRklnXpA6hbxWJRw8PD2rt3r7Zt26bx8XH19fVJknp6emo8HbAyR8SaH7SrqysmJibW/LjAlSgUChodHVV3d/fCtlKppIGBAR05cqSGkwEX2D4YEcsuMRNqNLxcLqdTp06pra1tYVu5XFZ7e7vm5uZqOBlwweVCzRo1Gl4+n9f4+PhF28bHx5XP52s0EbA6hBoNb3h4WH19fSqVSiqXyyqVSurr69Pw8HCtRwMy4cVENLzzLxgODAxoampK+XxeO3fu5IVE1A3WqAEgAaxRA0AdI9QAkDhCDQCJI9QAkDhCDQCJI9QAkDhCDQCJI9QAkDhCDQCJI9QAkDhCDQCJI9QAkDhCDQCJI9QAkDhCjabAXchRz7hxABoedyFHvePGAWh43IUc9YC7kKOpcRdy1APu8IKmxl3IUe8INRoedyFHvePFRDQ87kKOescaNQAkgDVqAKhjhBoAEkeoASBxhBoAEkeoASBxhBoAEkeoASBxmUNtO2d70vZnqzkQAOBiqzmjHpQ0Va1BAADLyxRq252SfkvSx6s7DgBgqaxn1H8laUjSuUvtYHuH7QnbEzMzM2syHAAgQ6ht/7ak4xFx8HL7RcSeiOiKiK6NGzeu2YAA0OyynFG/QdLv2j4m6RFJb7L9t1WdCgCwYMVQR8T7I6IzIjZLepukf4uIt1d9MgCAJN5HDQDJW9WNAyLiS5K+VJVJAADL4owaABJHqAEgcYQaABJHqAEgcYQaABJHqNEUisWiCoWCcrmcCoWCisVirUcCMlvV2/OAelQsFjU8PKy9e/dq27ZtGh8fV19fnySpp6enxtMBK3NErPlBu7q6YmJiYs2PC1yJQqGg0dFRdXd3L2wrlUoaGBjQkSNHajgZcIHtgxHRtexzhBqNLpfL6dSpU2pra1vYVi6X1d7errm5uRpOBlxwuVCzRo2Gl8/nNT4+ftG28fFx5fP5Gk0ErA6hRsMbHh5WX1+fSqWSyuWySqWS+vr6NDw8XOvRgEx4MREN7/wLhgMDA5qamlI+n9fOnTt5IRF1gzVqAEgAa9QAUMcINQAkjlADQOIINQAkjlADQOIINQAkjlADQOIINQAkjlADQOIINQAkjlADQOIINQAkjlADQOIINQAkjlADQOIINQAkjlADQOIINZpCsVhUoVBQLpdToVBQsVis9UhAZoQaDa9YLGpwcFCzs7OKCM3OzmpwcJBYo24QajS8oaEh5XI5jY2N6fTp0xobG1Mul9PQ0FCtRwMyIdRoeNPT09q/f7+6u7vV1tam7u5u7d+/X9PT07UeDciEUANA4gg1Gl5nZ6e2b9+uUqmkcrmsUqmk7du3q7Ozs9ajAZkQajS8Xbt26ezZs+rt7VV7e7t6e3t19uxZ7dq1q9ajAZmsGGrbL7Vdsj1l+ynbg9diMGCt9PT0aGRkRB0dHZKkjo4OjYyMqKenp8aTAdk4Ii6/g/0iSS+KiG/Yvk7SQUl3RcTRS/1MV1dXTExMrO2kANDAbB+MiK7lnlvxjDoifhQR36g8PilpStJL1nZEoLq44AX1rHU1O9veLGmrpCeWeW6HpB2StGnTpjUYDVgbxWJRw8PD2rt3r7Zt26bx8XH19fVJEssfqAsrLn0s7Gg/X9KXJe2MiE9dbl+WPpCSQqGg0dFRdXd3L2wrlUoaGBjQkSNHajgZcMHllj4yhdp2m6TPSvpCRPzlSvsTaqQkl8vp1KlTamtrW9hWLpfV3t6uubm5Gk4GXHBVa9S2LWmvpKkskQZSk8/n9dBDD120Rv3QQw8pn8/XejQgkyzvo36DpHdIepPtQ5V/v1nluYA1093drYcffli9vb06efKkent79fDDD1+0FAKkLPMa9Wqw9IGUFAoF3XzzzTpw4IBOnz6t9evX64477tC3v/1t1qiRjKta+gDq3dGjR3X48GEdOHBAZ86c0YEDB3T48GEdPXrJSwGApBBqNLx169apv7//ok/P6+/v17p162o9GpAJoUbDO3PmjEZHRy/6UKbR0VGdOXOm1qMBmazqghegHt1666266667NDAwoKmpKeXzed1///167LHHaj0akAmhRsMbHh7W4OCgOjo6Fm7FtWfPHo2MjNR6NCATQo2mcPLkSc3MzEiSjh07pvb29hpPBGTHGjUaXn9/v8rlsnbv3q3Z2Vnt3r1b5XJZ/f39tR4NyIRQo+GdOHFC9957r8bGxnTddddpbGxM9957r06cOFHr0YBMCDWawuOPP67Z2VlJ0uzsrB5//PEaTwRkR6jRFE6ePKmBgYGLvgL1gkvI0fBsy7ZuvPFGPfvss7rpppt0/PhxRYSq8d8/cCW4hBxNb+vWrTp+/Lgk6fjx49q6dWuNJwKyI9RoeNdff70mJyd14403LpxZT05O6vrrr6/1aEAmhBpNhaUO1CNCjYZ34sSJZZc+eHse6gWhRlOYnJxUS8v8f+4tLS2anJys8URAdlxCjqYQEQv3R+Q+iag3nFEDQOIINZrGhg0bZFsbNmyo9SjAqhBqNI0HH3xQP/vZz/Tggw/WehRgVbgyEQ3P9iWf4+16SAVXJgJAHSPUAJA4Qo2mkMvlLvs9kDJCjaawZcsW3XbbbWppadFtt92mLVu21HokIDMueEFTOHTo0MLjp556qoaTAKvHGTUAJI5QA0DiCDWaQktLi9ra2iRJbW1tCx/QBNQD1qjRFM6dO6dz585Jksrlco2nAVaH0woASByhBoDEEWoASByhBoDEEWoASByhBoDEEWoASFymUNt+i+1v2v6O7fdVeygAwAUrhtp2TtJHJN0h6VZJPbZvrfZgAIB5Wc6of0XSdyLiuxFxRtIjku6s7lgAgPOyXEL+EknfX/T9tKTXLd3J9g5JOyRp06ZNazIcmsuWfdX5jOjCJwrX/Hc+uf3JqhwXzSlLqJe7M+jP3RE0IvZI2iPN39z2KudCE6pW3Li5LepdlqWPaUkvXfR9p6QfVmccAMBSWUL9dUk323657XWS3ibpn6s7FrB2LnXWzNk06sWKSx8RcdZ2v6QvSMpJGosI7mWEukKUUc8yfR51RHxO0ueqPAsAYBlcmQgAiSPUAJA4Qg0AiSPUAJA4V+PVcNszkr635gcGrt4Nkn5c6yGAZbwsIjYu90RVQg2kyvZERHTVeg5gNVj6AIDEEWoASByhRrPZU+sBgNVijRoAEscZNQAkjlADQOIINQAkjlAjWbbfajtsv6ryfYvtv7Z9xPaTtr9u++WV547ZvqHy+LW2n7a9dYXjf9r2V5ds+9PK73zlom3vrmzrsv2E7UO2n7E9U3l8yPbmtf77gfMINVLWI2lc8zerkKT7JL1Y0u0RsUXSWyX9ZPEP2L5d0qOS7ouIyUsd2PYLJL1G0gvOx36RJxf9Tkm6R9JRSYqI10XEqyX9iaRPRsSrK/+OXdmfCKyMUCNJtp8v6Q2S+nQhmi+S9KOIOCdJETEdEf+76Mfykh6T9I6I+NoKv+JuSZ+R9IgujrIqx7izMscrJP1U0syV/zXA1SHUSNVdkj4fEd+SdML2ayT9vaTfqSw17F5maePTkvojYjzD8XskFSv/epY895yk79suVJ775NX8IcDVItRIVY/mz3ZV+doTEdOSbpH0fknnJH3R9psX/cy/SvoD27nLHdj2TZJeKWm88j+Cs5UoL3b+TPsuSf90tX8McDUINZJj+4WS3iTp47aPSXqvpPtsOyJOR8SBiHivpD/TfEjP6698/egKv+I+SRskPV05/mb9/PLHZyS9Q9IzEfHcVfw5wFUj1EjRPZL2R8TLImJzRLxU0tOS3mj7xdL8O0Ak3a6LP073nObPxG+x/cHLHL9H0lsqx94s6bVaEuqI+D9Jfyxp5xr9TcAVy3RzW+Aa65H0F0u2/aOkT2h+vXp9ZdvXJH148U4Rcdr2nZK+bPvZiPjI4ucrb6PbJOk/F/3M07afs/26Jcd6REAC+KwPAEgcSx8AkDiWPtCwbL9L0uCSzf8REX9Yi3mAK8XSBwAkjqUPAEgcoQaAxBFqAEgcoQaAxP0/Ib4V6LVgD6MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looking at ASK_AMT\n",
    "print(application_df.ASK_AMT.describe())\n",
    "application_df.ASK_AMT.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                     0.0   \n",
       "1       1   108590              1                     0.0   \n",
       "2       1     5000              0                     0.0   \n",
       "3       1     6692              1                     0.0   \n",
       "4       1   142590              1                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                   1.0                   0.0                  0.0   \n",
       "1                   0.0                   0.0                  1.0   \n",
       "2                   0.0                   0.0                  0.0   \n",
       "3                   0.0                   0.0                  1.0   \n",
       "4                   0.0                   0.0                  1.0   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  0.0                  0.0                  0.0  ...   \n",
       "2                  0.0                  1.0                  0.0  ...   \n",
       "3                  0.0                  0.0                  0.0  ...   \n",
       "4                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce/filter out outliers noisy variables from features ASK_AMT, using IQR and zscore \n",
    "application_df = application_df[(np.abs(stats.zscore(application_df.ASK_AMT)) <= 3)]\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  \\\n",
       "0     5000              1                     0.0                   1.0   \n",
       "1   108590              1                     0.0                   0.0   \n",
       "2     5000              0                     0.0                   0.0   \n",
       "3     6692              1                     0.0                   0.0   \n",
       "4   142590              1                     0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                   0.0                  0.0                  0.0   \n",
       "1                   0.0                  1.0                  0.0   \n",
       "2                   0.0                  0.0                  0.0   \n",
       "3                   0.0                  1.0                  0.0   \n",
       "4                   0.0                  1.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  0.0                  0.0                  0.0  ...   \n",
       "2                  1.0                  0.0                  0.0  ...   \n",
       "3                  0.0                  0.0                  0.0  ...   \n",
       "4                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "   ORGANIZATION_Trust  INCOME_AMT_0  INCOME_AMT_1-9999  \\\n",
       "0                 0.0           1.0                0.0   \n",
       "1                 0.0           0.0                1.0   \n",
       "2                 0.0           1.0                0.0   \n",
       "3                 1.0           0.0                0.0   \n",
       "4                 1.0           0.0                0.0   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                     0.0                       0.0                 0.0   \n",
       "1                     0.0                       0.0                 0.0   \n",
       "2                     0.0                       0.0                 0.0   \n",
       "3                     1.0                       0.0                 0.0   \n",
       "4                     0.0                       1.0                 0.0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0               0.0                     0.0              0.0   \n",
       "1               0.0                     0.0              0.0   \n",
       "2               0.0                     0.0              0.0   \n",
       "3               0.0                     0.0              0.0   \n",
       "4               0.0                     0.0              0.0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing other low-impact features\n",
    "application_df = application_df.drop(columns = ['STATUS','SPECIAL_CONSIDERATIONS_Y', 'SPECIAL_CONSIDERATIONS_N'])\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "#  Remove IS_SUCCESSFUL target from features data\n",
    "y = application_df.IS_SUCCESSFUL.values\n",
    "X = application_df.drop(columns=\"IS_SUCCESSFUL\").values\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile, Train and Evaluate the Model\n",
    "### Attempt-1: To achieve a target predictive Model Accuracy > 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 90)                3510      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                2730      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 6,271\n",
      "Trainable params: 6,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net. the number of input features and the hidden nodes for each layer.\n",
    "# A good rule of thumb for a basic neural network is to have two to three times the amount of neurons in \n",
    "# the hidden layer as the number of inputs.\n",
    "# And, even the most complex interactions can be characterized by as few as three hidden layers.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 90\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "803/803 [==============================] - 1s 893us/step - loss: 0.5734 - accuracy: 0.7186\n",
      "Epoch 2/50\n",
      "803/803 [==============================] - 1s 857us/step - loss: 0.5581 - accuracy: 0.7273\n",
      "Epoch 3/50\n",
      "803/803 [==============================] - 1s 979us/step - loss: 0.5547 - accuracy: 0.7296\n",
      "Epoch 4/50\n",
      "803/803 [==============================] - 1s 858us/step - loss: 0.5536 - accuracy: 0.7301\n",
      "Epoch 5/50\n",
      "803/803 [==============================] - 1s 884us/step - loss: 0.5519 - accuracy: 0.7320\n",
      "Epoch 6/50\n",
      "803/803 [==============================] - 1s 868us/step - loss: 0.5517 - accuracy: 0.7321\n",
      "Epoch 7/50\n",
      "803/803 [==============================] - 1s 919us/step - loss: 0.5509 - accuracy: 0.7315\n",
      "Epoch 8/50\n",
      "803/803 [==============================] - 1s 912us/step - loss: 0.5499 - accuracy: 0.7323\n",
      "Epoch 9/50\n",
      "803/803 [==============================] - 1s 891us/step - loss: 0.5496 - accuracy: 0.7317\n",
      "Epoch 10/50\n",
      "803/803 [==============================] - 1s 868us/step - loss: 0.5490 - accuracy: 0.7326\n",
      "Epoch 11/50\n",
      "803/803 [==============================] - 1s 876us/step - loss: 0.5491 - accuracy: 0.7333\n",
      "Epoch 12/50\n",
      "803/803 [==============================] - 1s 867us/step - loss: 0.5483 - accuracy: 0.7333\n",
      "Epoch 13/50\n",
      "803/803 [==============================] - 1s 879us/step - loss: 0.5477 - accuracy: 0.7339\n",
      "Epoch 14/50\n",
      "803/803 [==============================] - 1s 857us/step - loss: 0.5474 - accuracy: 0.7342\n",
      "Epoch 15/50\n",
      "803/803 [==============================] - 1s 864us/step - loss: 0.5466 - accuracy: 0.7343\n",
      "Epoch 16/50\n",
      "803/803 [==============================] - 1s 867us/step - loss: 0.5470 - accuracy: 0.7344\n",
      "Epoch 17/50\n",
      "803/803 [==============================] - 1s 941us/step - loss: 0.5465 - accuracy: 0.7349\n",
      "Epoch 18/50\n",
      "803/803 [==============================] - 1s 859us/step - loss: 0.5461 - accuracy: 0.7355\n",
      "Epoch 19/50\n",
      "803/803 [==============================] - 1s 866us/step - loss: 0.5455 - accuracy: 0.7350\n",
      "Epoch 20/50\n",
      "803/803 [==============================] - 1s 882us/step - loss: 0.5458 - accuracy: 0.7350\n",
      "Epoch 21/50\n",
      "803/803 [==============================] - 1s 866us/step - loss: 0.5450 - accuracy: 0.7359\n",
      "Epoch 22/50\n",
      "803/803 [==============================] - 1s 889us/step - loss: 0.5449 - accuracy: 0.7359\n",
      "Epoch 23/50\n",
      "803/803 [==============================] - 1s 879us/step - loss: 0.5448 - accuracy: 0.7355\n",
      "Epoch 24/50\n",
      "803/803 [==============================] - 1s 879us/step - loss: 0.5446 - accuracy: 0.7371\n",
      "Epoch 25/50\n",
      "803/803 [==============================] - 1s 863us/step - loss: 0.5443 - accuracy: 0.7352\n",
      "Epoch 26/50\n",
      "803/803 [==============================] - 1s 936us/step - loss: 0.5438 - accuracy: 0.7369\n",
      "Epoch 27/50\n",
      "803/803 [==============================] - 1s 904us/step - loss: 0.5437 - accuracy: 0.7368\n",
      "Epoch 28/50\n",
      "803/803 [==============================] - 1s 873us/step - loss: 0.5434 - accuracy: 0.7363\n",
      "Epoch 29/50\n",
      "803/803 [==============================] - 1s 872us/step - loss: 0.5431 - accuracy: 0.7361\n",
      "Epoch 30/50\n",
      "803/803 [==============================] - 1s 898us/step - loss: 0.5429 - accuracy: 0.7369\n",
      "Epoch 31/50\n",
      "803/803 [==============================] - 1s 964us/step - loss: 0.5433 - accuracy: 0.7367\n",
      "Epoch 32/50\n",
      "803/803 [==============================] - 1s 891us/step - loss: 0.5423 - accuracy: 0.7371\n",
      "Epoch 33/50\n",
      "803/803 [==============================] - 1s 958us/step - loss: 0.5428 - accuracy: 0.7367\n",
      "Epoch 34/50\n",
      "803/803 [==============================] - 1s 857us/step - loss: 0.5425 - accuracy: 0.7370\n",
      "Epoch 35/50\n",
      "803/803 [==============================] - 1s 840us/step - loss: 0.5421 - accuracy: 0.7370\n",
      "Epoch 36/50\n",
      "803/803 [==============================] - 1s 918us/step - loss: 0.5422 - accuracy: 0.7368\n",
      "Epoch 37/50\n",
      "803/803 [==============================] - 1s 843us/step - loss: 0.5417 - accuracy: 0.7382\n",
      "Epoch 38/50\n",
      "803/803 [==============================] - 1s 789us/step - loss: 0.5421 - accuracy: 0.7384\n",
      "Epoch 39/50\n",
      "803/803 [==============================] - 1s 837us/step - loss: 0.5415 - accuracy: 0.7377\n",
      "Epoch 40/50\n",
      "803/803 [==============================] - 1s 1000us/step - loss: 0.5415 - accuracy: 0.7384\n",
      "Epoch 41/50\n",
      "803/803 [==============================] - 1s 838us/step - loss: 0.5413 - accuracy: 0.7368\n",
      "Epoch 42/50\n",
      "803/803 [==============================] - 1s 758us/step - loss: 0.5411 - accuracy: 0.7383\n",
      "Epoch 43/50\n",
      "803/803 [==============================] - 1s 883us/step - loss: 0.5409 - accuracy: 0.7385\n",
      "Epoch 44/50\n",
      "803/803 [==============================] - 1s 791us/step - loss: 0.5408 - accuracy: 0.7379\n",
      "Epoch 45/50\n",
      "803/803 [==============================] - 1s 748us/step - loss: 0.5408 - accuracy: 0.7387\n",
      "Epoch 46/50\n",
      "803/803 [==============================] - 1s 810us/step - loss: 0.5406 - accuracy: 0.7389\n",
      "Epoch 47/50\n",
      "803/803 [==============================] - 1s 806us/step - loss: 0.5407 - accuracy: 0.7381\n",
      "Epoch 48/50\n",
      "803/803 [==============================] - 1s 768us/step - loss: 0.5402 - accuracy: 0.7380\n",
      "Epoch 49/50\n",
      "803/803 [==============================] - 1s 894us/step - loss: 0.5403 - accuracy: 0.7388\n",
      "Epoch 50/50\n",
      "803/803 [==============================] - 1s 802us/step - loss: 0.5401 - accuracy: 0.7386\n"
     ]
    }
   ],
   "source": [
    "# Compile and train the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5638 - accuracy: 0.7255\n",
      "Loss: 0.5638344883918762, Accuracy: 0.7255313992500305\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a callback to save the model's weights every 5 epochs, and \n",
    "#### Save and export the results to an HDF5 file, Hierarchical Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import checkpoint dependencies\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"AlphabetSoupCharity_Optimization.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt-2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5688 - accuracy: 0.7209\n",
      "Epoch 2/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5595 - accuracy: 0.7280\n",
      "Epoch 3/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5569 - accuracy: 0.7299\n",
      "Epoch 4/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5535 - accuracy: 0.7306\n",
      "Epoch 5/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5527 - accuracy: 0.7297\n",
      "Epoch 6/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5519 - accuracy: 0.7321\n",
      "Epoch 7/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5503 - accuracy: 0.7331\n",
      "Epoch 8/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5505 - accuracy: 0.7317\n",
      "Epoch 9/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5492 - accuracy: 0.7331\n",
      "Epoch 10/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5486 - accuracy: 0.7336\n",
      "Epoch 11/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5480 - accuracy: 0.7337\n",
      "Epoch 12/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.7343\n",
      "Epoch 13/300\n",
      "803/803 [==============================] - 1s 2ms/step - loss: 0.5467 - accuracy: 0.7349: 0s - loss: 0.5472 - accuracy: 0.\n",
      "Epoch 14/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5463 - accuracy: 0.7354\n",
      "Epoch 15/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5459 - accuracy: 0.7358\n",
      "Epoch 16/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7352\n",
      "Epoch 17/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7359\n",
      "Epoch 18/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7368\n",
      "Epoch 19/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5440 - accuracy: 0.7372\n",
      "Epoch 20/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.7361\n",
      "Epoch 21/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7363\n",
      "Epoch 22/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7362\n",
      "Epoch 23/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7368\n",
      "Epoch 24/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7365\n",
      "Epoch 25/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7375\n",
      "Epoch 26/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7378\n",
      "Epoch 27/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7379\n",
      "Epoch 28/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7377: 0s - loss:\n",
      "Epoch 29/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5411 - accuracy: 0.7374\n",
      "Epoch 30/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5412 - accuracy: 0.7386\n",
      "Epoch 31/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5408 - accuracy: 0.7386\n",
      "Epoch 32/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5407 - accuracy: 0.7386\n",
      "Epoch 33/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5404 - accuracy: 0.7386\n",
      "Epoch 34/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5400 - accuracy: 0.7394\n",
      "Epoch 35/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5402 - accuracy: 0.7385\n",
      "Epoch 36/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5398 - accuracy: 0.7387\n",
      "Epoch 37/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5395 - accuracy: 0.7394\n",
      "Epoch 38/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5392 - accuracy: 0.7393\n",
      "Epoch 39/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5394 - accuracy: 0.7391\n",
      "Epoch 40/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7397\n",
      "Epoch 41/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7382\n",
      "Epoch 42/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7401\n",
      "Epoch 43/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7394\n",
      "Epoch 44/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5381 - accuracy: 0.7400\n",
      "Epoch 45/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5382 - accuracy: 0.7399\n",
      "Epoch 46/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.7398\n",
      "Epoch 47/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5382 - accuracy: 0.7396\n",
      "Epoch 48/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.7407\n",
      "Epoch 49/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7386\n",
      "Epoch 50/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7397\n",
      "Epoch 51/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5378 - accuracy: 0.7407\n",
      "Epoch 52/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5378 - accuracy: 0.7407\n",
      "Epoch 53/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5375 - accuracy: 0.7407\n",
      "Epoch 54/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7398\n",
      "Epoch 55/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7414\n",
      "Epoch 56/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5370 - accuracy: 0.7401\n",
      "Epoch 57/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7398\n",
      "Epoch 58/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7405\n",
      "Epoch 59/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7412\n",
      "Epoch 60/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5386 - accuracy: 0.7407\n",
      "Epoch 61/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7400\n",
      "Epoch 62/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7402\n",
      "Epoch 63/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5368 - accuracy: 0.7410\n",
      "Epoch 64/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7404\n",
      "Epoch 65/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7399\n",
      "Epoch 66/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7406\n",
      "Epoch 67/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7403\n",
      "Epoch 68/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7412\n",
      "Epoch 69/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7405\n",
      "Epoch 70/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5383 - accuracy: 0.7417\n",
      "Epoch 71/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5371 - accuracy: 0.7410\n",
      "Epoch 72/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7405\n",
      "Epoch 73/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7407\n",
      "Epoch 74/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5347 - accuracy: 0.7420\n",
      "Epoch 75/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7406\n",
      "Epoch 76/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7409\n",
      "Epoch 77/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7410\n",
      "Epoch 78/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7414\n",
      "Epoch 79/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7409\n",
      "Epoch 80/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5347 - accuracy: 0.7415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7414\n",
      "Epoch 82/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7398\n",
      "Epoch 83/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7409\n",
      "Epoch 84/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7396\n",
      "Epoch 85/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7406\n",
      "Epoch 86/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7407\n",
      "Epoch 87/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7413\n",
      "Epoch 88/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7405\n",
      "Epoch 89/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7418\n",
      "Epoch 90/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7409\n",
      "Epoch 91/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7409\n",
      "Epoch 92/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7423\n",
      "Epoch 93/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7412\n",
      "Epoch 94/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7416\n",
      "Epoch 95/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7407\n",
      "Epoch 96/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5347 - accuracy: 0.7409\n",
      "Epoch 97/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7413\n",
      "Epoch 98/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5348 - accuracy: 0.7411\n",
      "Epoch 99/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7407: 0s - loss: 0\n",
      "Epoch 100/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5347 - accuracy: 0.7413\n",
      "Epoch 101/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5343 - accuracy: 0.7416\n",
      "Epoch 102/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7407\n",
      "Epoch 103/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7418\n",
      "Epoch 104/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5348 - accuracy: 0.7415\n",
      "Epoch 105/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7416\n",
      "Epoch 106/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7406\n",
      "Epoch 107/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7416\n",
      "Epoch 108/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5348 - accuracy: 0.7414\n",
      "Epoch 109/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5344 - accuracy: 0.7417\n",
      "Epoch 110/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7410\n",
      "Epoch 111/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5348 - accuracy: 0.7417\n",
      "Epoch 112/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7414\n",
      "Epoch 113/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7414\n",
      "Epoch 114/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5345 - accuracy: 0.7417\n",
      "Epoch 115/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5344 - accuracy: 0.7412\n",
      "Epoch 116/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7400\n",
      "Epoch 117/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7398\n",
      "Epoch 118/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7414\n",
      "Epoch 119/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7404\n",
      "Epoch 120/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7396\n",
      "Epoch 121/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7417\n",
      "Epoch 122/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7403\n",
      "Epoch 123/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7408\n",
      "Epoch 124/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5345 - accuracy: 0.7415\n",
      "Epoch 125/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5340 - accuracy: 0.7414\n",
      "Epoch 126/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7411\n",
      "Epoch 127/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7413\n",
      "Epoch 128/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7416\n",
      "Epoch 129/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7418\n",
      "Epoch 130/300\n",
      "803/803 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7422\n",
      "Epoch 131/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7422\n",
      "Epoch 132/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7410\n",
      "Epoch 133/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7421\n",
      "Epoch 134/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7414\n",
      "Epoch 135/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7403\n",
      "Epoch 136/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7417\n",
      "Epoch 137/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7414\n",
      "Epoch 138/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7405\n",
      "Epoch 139/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7416\n",
      "Epoch 140/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5344 - accuracy: 0.7416\n",
      "Epoch 141/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7417\n",
      "Epoch 142/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5375 - accuracy: 0.7411\n",
      "Epoch 143/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5385 - accuracy: 0.7413\n",
      "Epoch 144/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5384 - accuracy: 0.7387\n",
      "Epoch 145/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7417\n",
      "Epoch 146/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7404\n",
      "Epoch 147/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7416\n",
      "Epoch 148/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7407\n",
      "Epoch 149/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7401\n",
      "Epoch 150/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7400\n",
      "Epoch 151/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7406\n",
      "Epoch 152/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7411\n",
      "Epoch 153/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7406\n",
      "Epoch 154/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7409\n",
      "Epoch 155/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7414\n",
      "Epoch 156/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7403\n",
      "Epoch 157/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7406\n",
      "Epoch 158/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7396\n",
      "Epoch 159/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7410\n",
      "Epoch 160/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7407\n",
      "Epoch 161/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7398\n",
      "Epoch 162/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7416\n",
      "Epoch 163/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7414\n",
      "Epoch 164/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7414\n",
      "Epoch 165/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7409\n",
      "Epoch 166/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7416\n",
      "Epoch 167/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7405\n",
      "Epoch 168/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7414\n",
      "Epoch 169/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7404\n",
      "Epoch 170/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7392\n",
      "Epoch 171/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5348 - accuracy: 0.7417\n",
      "Epoch 172/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7410\n",
      "Epoch 173/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7400\n",
      "Epoch 174/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7410\n",
      "Epoch 175/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7417\n",
      "Epoch 176/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5341 - accuracy: 0.7421\n",
      "Epoch 177/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5368 - accuracy: 0.7416\n",
      "Epoch 178/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7401\n",
      "Epoch 179/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5370 - accuracy: 0.7401\n",
      "Epoch 180/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5371 - accuracy: 0.7396\n",
      "Epoch 181/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7406\n",
      "Epoch 182/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7395\n",
      "Epoch 183/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7407\n",
      "Epoch 184/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7401\n",
      "Epoch 185/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7401\n",
      "Epoch 186/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5377 - accuracy: 0.7407\n",
      "Epoch 187/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7413\n",
      "Epoch 188/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7412\n",
      "Epoch 189/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7399\n",
      "Epoch 190/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7402\n",
      "Epoch 191/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7412\n",
      "Epoch 192/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7407\n",
      "Epoch 193/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7404\n",
      "Epoch 194/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7410\n",
      "Epoch 195/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5375 - accuracy: 0.7396\n",
      "Epoch 196/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7412\n",
      "Epoch 197/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7419\n",
      "Epoch 198/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5374 - accuracy: 0.7401\n",
      "Epoch 199/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7408\n",
      "Epoch 200/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7400\n",
      "Epoch 201/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7415\n",
      "Epoch 202/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7402\n",
      "Epoch 203/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7402\n",
      "Epoch 204/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7418\n",
      "Epoch 205/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7405\n",
      "Epoch 206/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7419\n",
      "Epoch 207/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5346 - accuracy: 0.7414\n",
      "Epoch 208/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7418\n",
      "Epoch 209/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7412\n",
      "Epoch 210/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7398\n",
      "Epoch 211/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7400\n",
      "Epoch 212/300\n",
      "803/803 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.73 - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7398\n",
      "Epoch 213/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7409\n",
      "Epoch 214/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5348 - accuracy: 0.7419\n",
      "Epoch 215/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7396\n",
      "Epoch 216/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5368 - accuracy: 0.7400\n",
      "Epoch 217/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7396\n",
      "Epoch 218/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.7397\n",
      "Epoch 219/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7396\n",
      "Epoch 220/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.7384\n",
      "Epoch 221/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7414\n",
      "Epoch 222/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7407\n",
      "Epoch 223/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7410\n",
      "Epoch 224/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7399\n",
      "Epoch 225/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7401\n",
      "Epoch 226/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5368 - accuracy: 0.7400\n",
      "Epoch 227/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7398\n",
      "Epoch 228/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7409\n",
      "Epoch 229/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7401\n",
      "Epoch 230/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5368 - accuracy: 0.7405\n",
      "Epoch 231/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5375 - accuracy: 0.7426\n",
      "Epoch 232/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7407\n",
      "Epoch 233/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7396\n",
      "Epoch 234/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7401\n",
      "Epoch 235/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7404\n",
      "Epoch 236/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7398\n",
      "Epoch 237/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7401\n",
      "Epoch 238/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7405\n",
      "Epoch 239/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7386\n",
      "Epoch 240/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7400\n",
      "Epoch 241/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7410\n",
      "Epoch 242/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7394\n",
      "Epoch 243/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7407\n",
      "Epoch 244/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7409\n",
      "Epoch 245/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7400\n",
      "Epoch 246/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5368 - accuracy: 0.7403\n",
      "Epoch 247/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7396\n",
      "Epoch 248/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7414\n",
      "Epoch 249/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7407\n",
      "Epoch 250/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7403\n",
      "Epoch 251/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7396\n",
      "Epoch 252/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7397\n",
      "Epoch 253/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7412\n",
      "Epoch 254/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7398\n",
      "Epoch 255/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7402\n",
      "Epoch 256/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7396\n",
      "Epoch 257/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7411: \n",
      "Epoch 258/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7414\n",
      "Epoch 259/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7415\n",
      "Epoch 260/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7398\n",
      "Epoch 261/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7393\n",
      "Epoch 262/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7399\n",
      "Epoch 263/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7389\n",
      "Epoch 264/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7399\n",
      "Epoch 265/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5379 - accuracy: 0.7393\n",
      "Epoch 266/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7394\n",
      "Epoch 267/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7400\n",
      "Epoch 268/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7402\n",
      "Epoch 269/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7413\n",
      "Epoch 270/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7399\n",
      "Epoch 271/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7389\n",
      "Epoch 272/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7402\n",
      "Epoch 273/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5370 - accuracy: 0.7398\n",
      "Epoch 274/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7412\n",
      "Epoch 275/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7388\n",
      "Epoch 276/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7411\n",
      "Epoch 277/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7382\n",
      "Epoch 278/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7402\n",
      "Epoch 279/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7396\n",
      "Epoch 280/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5377 - accuracy: 0.7388\n",
      "Epoch 281/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7398\n",
      "Epoch 282/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7404\n",
      "Epoch 283/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5396 - accuracy: 0.7402\n",
      "Epoch 284/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5412 - accuracy: 0.7384\n",
      "Epoch 285/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7396\n",
      "Epoch 286/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7388\n",
      "Epoch 287/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7385\n",
      "Epoch 288/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5410 - accuracy: 0.7401\n",
      "Epoch 289/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7389\n",
      "Epoch 290/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.7367\n",
      "Epoch 291/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5401 - accuracy: 0.7387\n",
      "Epoch 292/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5400 - accuracy: 0.7385\n",
      "Epoch 293/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7379\n",
      "Epoch 294/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5406 - accuracy: 0.7386\n",
      "Epoch 295/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5404 - accuracy: 0.7394\n",
      "Epoch 296/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5391 - accuracy: 0.7380\n",
      "Epoch 297/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7386\n",
      "Epoch 298/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5400 - accuracy: 0.7382\n",
      "Epoch 299/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5409 - accuracy: 0.7375\n",
      "Epoch 300/300\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5405 - accuracy: 0.7390\n",
      "268/268 - 0s - loss: 0.5723 - accuracy: 0.7209\n",
      "Loss: 0.5722991824150085, Accuracy: 0.7208595871925354\n"
     ]
    }
   ],
   "source": [
    "# Define the model \n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 220\n",
    "hidden_nodes_layer2 = 120\n",
    "hidden_nodes_layer3 = 60\n",
    "hidden_nodes_layer4 = 60\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile and train the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=300)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt-3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "803/803 [==============================] - 1s 841us/step - loss: 0.5688 - accuracy: 0.7233\n",
      "Epoch 2/50\n",
      "803/803 [==============================] - 1s 902us/step - loss: 0.5580 - accuracy: 0.7284\n",
      "Epoch 3/50\n",
      "803/803 [==============================] - 1s 924us/step - loss: 0.5554 - accuracy: 0.7305\n",
      "Epoch 4/50\n",
      "803/803 [==============================] - 1s 857us/step - loss: 0.5536 - accuracy: 0.7302\n",
      "Epoch 5/50\n",
      "803/803 [==============================] - 1s 827us/step - loss: 0.5518 - accuracy: 0.7299\n",
      "Epoch 6/50\n",
      "803/803 [==============================] - 1s 862us/step - loss: 0.5508 - accuracy: 0.7321\n",
      "Epoch 7/50\n",
      "803/803 [==============================] - 1s 876us/step - loss: 0.5496 - accuracy: 0.7315\n",
      "Epoch 8/50\n",
      "803/803 [==============================] - 1s 830us/step - loss: 0.5488 - accuracy: 0.7334\n",
      "Epoch 9/50\n",
      "803/803 [==============================] - 1s 929us/step - loss: 0.5477 - accuracy: 0.7344\n",
      "Epoch 10/50\n",
      "803/803 [==============================] - 1s 917us/step - loss: 0.5467 - accuracy: 0.7346\n",
      "Epoch 11/50\n",
      "803/803 [==============================] - 1s 838us/step - loss: 0.5465 - accuracy: 0.7334\n",
      "Epoch 12/50\n",
      "803/803 [==============================] - 1s 827us/step - loss: 0.5461 - accuracy: 0.7335\n",
      "Epoch 13/50\n",
      "803/803 [==============================] - 1s 869us/step - loss: 0.5452 - accuracy: 0.7350\n",
      "Epoch 14/50\n",
      "803/803 [==============================] - 1s 851us/step - loss: 0.5450 - accuracy: 0.7349\n",
      "Epoch 15/50\n",
      "803/803 [==============================] - 1s 894us/step - loss: 0.5444 - accuracy: 0.7350\n",
      "Epoch 16/50\n",
      "803/803 [==============================] - 1s 862us/step - loss: 0.5442 - accuracy: 0.7343\n",
      "Epoch 17/50\n",
      "803/803 [==============================] - 1s 919us/step - loss: 0.5435 - accuracy: 0.7358\n",
      "Epoch 18/50\n",
      "803/803 [==============================] - 1s 855us/step - loss: 0.5433 - accuracy: 0.7359\n",
      "Epoch 19/50\n",
      "803/803 [==============================] - 1s 887us/step - loss: 0.5425 - accuracy: 0.7365\n",
      "Epoch 20/50\n",
      "803/803 [==============================] - 1s 856us/step - loss: 0.5422 - accuracy: 0.7375\n",
      "Epoch 21/50\n",
      "803/803 [==============================] - 1s 889us/step - loss: 0.5420 - accuracy: 0.7371\n",
      "Epoch 22/50\n",
      "803/803 [==============================] - 1s 986us/step - loss: 0.5419 - accuracy: 0.7369\n",
      "Epoch 23/50\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.7374\n",
      "Epoch 24/50\n",
      "803/803 [==============================] - 1s 990us/step - loss: 0.5409 - accuracy: 0.7380\n",
      "Epoch 25/50\n",
      "803/803 [==============================] - 1s 903us/step - loss: 0.5408 - accuracy: 0.7386\n",
      "Epoch 26/50\n",
      "803/803 [==============================] - 1s 898us/step - loss: 0.5406 - accuracy: 0.7379\n",
      "Epoch 27/50\n",
      "803/803 [==============================] - 1s 907us/step - loss: 0.5402 - accuracy: 0.7384\n",
      "Epoch 28/50\n",
      "803/803 [==============================] - 1s 887us/step - loss: 0.5398 - accuracy: 0.73840s - loss:\n",
      "Epoch 29/50\n",
      "803/803 [==============================] - 1s 878us/step - loss: 0.5399 - accuracy: 0.7375\n",
      "Epoch 30/50\n",
      "803/803 [==============================] - 1s 887us/step - loss: 0.5394 - accuracy: 0.7403\n",
      "Epoch 31/50\n",
      "803/803 [==============================] - 1s 892us/step - loss: 0.5393 - accuracy: 0.7388\n",
      "Epoch 32/50\n",
      "803/803 [==============================] - 1s 891us/step - loss: 0.5390 - accuracy: 0.7394\n",
      "Epoch 33/50\n",
      "803/803 [==============================] - 1s 882us/step - loss: 0.5390 - accuracy: 0.7384\n",
      "Epoch 34/50\n",
      "803/803 [==============================] - 1s 900us/step - loss: 0.5386 - accuracy: 0.7392\n",
      "Epoch 35/50\n",
      "803/803 [==============================] - 1s 888us/step - loss: 0.5387 - accuracy: 0.7388\n",
      "Epoch 36/50\n",
      "803/803 [==============================] - 1s 945us/step - loss: 0.5389 - accuracy: 0.7387\n",
      "Epoch 37/50\n",
      "803/803 [==============================] - 1s 898us/step - loss: 0.5383 - accuracy: 0.7392\n",
      "Epoch 38/50\n",
      "803/803 [==============================] - 1s 901us/step - loss: 0.5380 - accuracy: 0.7392\n",
      "Epoch 39/50\n",
      "803/803 [==============================] - 1s 892us/step - loss: 0.5381 - accuracy: 0.7393\n",
      "Epoch 40/50\n",
      "803/803 [==============================] - 1s 934us/step - loss: 0.5379 - accuracy: 0.7388\n",
      "Epoch 41/50\n",
      "803/803 [==============================] - 1s 912us/step - loss: 0.5376 - accuracy: 0.7401\n",
      "Epoch 42/50\n",
      "803/803 [==============================] - 1s 917us/step - loss: 0.5372 - accuracy: 0.7394\n",
      "Epoch 43/50\n",
      "803/803 [==============================] - 1s 975us/step - loss: 0.5373 - accuracy: 0.7398\n",
      "Epoch 44/50\n",
      "803/803 [==============================] - 1s 905us/step - loss: 0.5371 - accuracy: 0.7408\n",
      "Epoch 45/50\n",
      "803/803 [==============================] - 1s 882us/step - loss: 0.5371 - accuracy: 0.7400\n",
      "Epoch 46/50\n",
      "803/803 [==============================] - 1s 883us/step - loss: 0.5370 - accuracy: 0.7394\n",
      "Epoch 47/50\n",
      "803/803 [==============================] - 1s 905us/step - loss: 0.5369 - accuracy: 0.7403\n",
      "Epoch 48/50\n",
      "803/803 [==============================] - 1s 876us/step - loss: 0.5368 - accuracy: 0.7403\n",
      "Epoch 49/50\n",
      "803/803 [==============================] - 1s 872us/step - loss: 0.5366 - accuracy: 0.7387\n",
      "Epoch 50/50\n",
      "803/803 [==============================] - 1s 900us/step - loss: 0.5365 - accuracy: 0.7399\n",
      "268/268 - 0s - loss: 0.5658 - accuracy: 0.7224\n",
      "Loss: 0.5657792687416077, Accuracy: 0.7223779559135437\n"
     ]
    }
   ],
   "source": [
    "# Define the model \n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 60\n",
    "hidden_nodes_layer2 = 40\n",
    "hidden_nodes_layer3 = 20\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile and train the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt-4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5735 - accuracy: 0.7203\n",
      "Epoch 2/50\n",
      "803/803 [==============================] - 1s 2ms/step - loss: 0.5596 - accuracy: 0.7278\n",
      "Epoch 3/50\n",
      "803/803 [==============================] - 1s 2ms/step - loss: 0.5566 - accuracy: 0.7301\n",
      "Epoch 4/50\n",
      "803/803 [==============================] - 1s 2ms/step - loss: 0.5551 - accuracy: 0.7314\n",
      "Epoch 5/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5531 - accuracy: 0.7328\n",
      "Epoch 6/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5529 - accuracy: 0.7305\n",
      "Epoch 7/50\n",
      "803/803 [==============================] - 1s 2ms/step - loss: 0.5510 - accuracy: 0.7320\n",
      "Epoch 8/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5505 - accuracy: 0.7321\n",
      "Epoch 9/50\n",
      "803/803 [==============================] - 1s 2ms/step - loss: 0.5498 - accuracy: 0.7326\n",
      "Epoch 10/50\n",
      "803/803 [==============================] - 1s 2ms/step - loss: 0.5492 - accuracy: 0.7343\n",
      "Epoch 11/50\n",
      "803/803 [==============================] - 1s 2ms/step - loss: 0.5495 - accuracy: 0.7329\n",
      "Epoch 12/50\n",
      "803/803 [==============================] - 1s 2ms/step - loss: 0.5474 - accuracy: 0.7349\n",
      "Epoch 13/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7358\n",
      "Epoch 14/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5471 - accuracy: 0.7356\n",
      "Epoch 15/50\n",
      "803/803 [==============================] - 1s 2ms/step - loss: 0.5467 - accuracy: 0.7349\n",
      "Epoch 16/50\n",
      "803/803 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7359\n",
      "Epoch 17/50\n",
      "803/803 [==============================] - 1s 2ms/step - loss: 0.5466 - accuracy: 0.7351\n",
      "Epoch 18/50\n",
      "803/803 [==============================] - 1s 2ms/step - loss: 0.5460 - accuracy: 0.7351\n",
      "Epoch 19/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7365\n",
      "Epoch 20/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7354\n",
      "Epoch 21/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7358\n",
      "Epoch 22/50\n",
      "803/803 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7362\n",
      "Epoch 23/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7365\n",
      "Epoch 24/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7368\n",
      "Epoch 25/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7370\n",
      "Epoch 26/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7379\n",
      "Epoch 27/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7382\n",
      "Epoch 28/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7375\n",
      "Epoch 29/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7375\n",
      "Epoch 30/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7373\n",
      "Epoch 31/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5409 - accuracy: 0.7382\n",
      "Epoch 32/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7384\n",
      "Epoch 33/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5408 - accuracy: 0.7386\n",
      "Epoch 34/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7386\n",
      "Epoch 35/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5405 - accuracy: 0.7383\n",
      "Epoch 36/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7364\n",
      "Epoch 37/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5400 - accuracy: 0.7387\n",
      "Epoch 38/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5399 - accuracy: 0.7391\n",
      "Epoch 39/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7382\n",
      "Epoch 40/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5402 - accuracy: 0.7386\n",
      "Epoch 41/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5398 - accuracy: 0.7366\n",
      "Epoch 42/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5390 - accuracy: 0.7380\n",
      "Epoch 43/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7381\n",
      "Epoch 44/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5386 - accuracy: 0.7400\n",
      "Epoch 45/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5393 - accuracy: 0.7391\n",
      "Epoch 46/50\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.5392 - accuracy: 0.7387\n",
      "Epoch 47/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5388 - accuracy: 0.7373\n",
      "Epoch 48/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5381 - accuracy: 0.7388\n",
      "Epoch 49/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7395\n",
      "Epoch 50/50\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.5388 - accuracy: 0.7387\n",
      "268/268 - 0s - loss: 0.5922 - accuracy: 0.7240\n",
      "Loss: 0.5921921133995056, Accuracy: 0.724013090133667\n"
     ]
    }
   ],
   "source": [
    "# Define the model \n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 60\n",
    "hidden_nodes_layer2 = 120\n",
    "hidden_nodes_layer3 = 240\n",
    "hidden_nodes_layer4 = 240\n",
    "hidden_nodes_layer5 = 120\n",
    "hidden_nodes_layer6 = 60\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# 4th hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\"))\n",
    "\n",
    "# 5th hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=\"relu\"))\n",
    "\n",
    "# 6th hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer6, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile and train the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt-5: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "803/803 [==============================] - 1s 777us/step - loss: 3.3737 - accuracy: 0.4281\n",
      "Epoch 2/100\n",
      "803/803 [==============================] - 1s 744us/step - loss: 2.7707 - accuracy: 0.4416\n",
      "Epoch 3/100\n",
      "803/803 [==============================] - 1s 811us/step - loss: 2.7022 - accuracy: 0.4549\n",
      "Epoch 4/100\n",
      "803/803 [==============================] - 1s 779us/step - loss: 2.4681 - accuracy: 0.4710\n",
      "Epoch 5/100\n",
      "803/803 [==============================] - 1s 820us/step - loss: 2.1928 - accuracy: 0.4764\n",
      "Epoch 6/100\n",
      "803/803 [==============================] - 1s 764us/step - loss: 2.0647 - accuracy: 0.5060\n",
      "Epoch 7/100\n",
      "803/803 [==============================] - 1s 754us/step - loss: 1.9332 - accuracy: 0.5988\n",
      "Epoch 8/100\n",
      "803/803 [==============================] - 1s 749us/step - loss: 1.8945 - accuracy: 0.6075\n",
      "Epoch 9/100\n",
      "803/803 [==============================] - 1s 809us/step - loss: 1.8551 - accuracy: 0.6087\n",
      "Epoch 10/100\n",
      "803/803 [==============================] - 1s 756us/step - loss: 1.7347 - accuracy: 0.6160\n",
      "Epoch 11/100\n",
      "803/803 [==============================] - 1s 727us/step - loss: 1.6470 - accuracy: 0.6344\n",
      "Epoch 12/100\n",
      "803/803 [==============================] - 1s 743us/step - loss: 1.4658 - accuracy: 0.6450\n",
      "Epoch 13/100\n",
      "803/803 [==============================] - 1s 745us/step - loss: 1.0301 - accuracy: 0.6508\n",
      "Epoch 14/100\n",
      "803/803 [==============================] - 1s 722us/step - loss: 0.9939 - accuracy: 0.6560\n",
      "Epoch 15/100\n",
      "803/803 [==============================] - 1s 781us/step - loss: 0.9741 - accuracy: 0.6627\n",
      "Epoch 16/100\n",
      "803/803 [==============================] - 1s 743us/step - loss: 0.9441 - accuracy: 0.6685\n",
      "Epoch 17/100\n",
      "803/803 [==============================] - 1s 768us/step - loss: 0.8976 - accuracy: 0.6955\n",
      "Epoch 18/100\n",
      "803/803 [==============================] - 1s 746us/step - loss: 0.8769 - accuracy: 0.7088\n",
      "Epoch 19/100\n",
      "803/803 [==============================] - 1s 755us/step - loss: 0.8419 - accuracy: 0.7100\n",
      "Epoch 20/100\n",
      "803/803 [==============================] - 1s 829us/step - loss: 0.8327 - accuracy: 0.7107\n",
      "Epoch 21/100\n",
      "803/803 [==============================] - 1s 746us/step - loss: 0.8059 - accuracy: 0.7113\n",
      "Epoch 22/100\n",
      "803/803 [==============================] - 1s 787us/step - loss: 0.6850 - accuracy: 0.7116\n",
      "Epoch 23/100\n",
      "803/803 [==============================] - 1s 753us/step - loss: 0.6779 - accuracy: 0.7115\n",
      "Epoch 24/100\n",
      "803/803 [==============================] - 1s 732us/step - loss: 0.6689 - accuracy: 0.7116\n",
      "Epoch 25/100\n",
      "803/803 [==============================] - 1s 888us/step - loss: 0.6621 - accuracy: 0.7115\n",
      "Epoch 26/100\n",
      "803/803 [==============================] - 1s 815us/step - loss: 0.6556 - accuracy: 0.7120\n",
      "Epoch 27/100\n",
      "803/803 [==============================] - 1s 773us/step - loss: 0.6404 - accuracy: 0.7124\n",
      "Epoch 28/100\n",
      "803/803 [==============================] - 1s 842us/step - loss: 0.6167 - accuracy: 0.7128\n",
      "Epoch 29/100\n",
      "803/803 [==============================] - 1s 874us/step - loss: 0.5969 - accuracy: 0.7130\n",
      "Epoch 30/100\n",
      "803/803 [==============================] - 1s 773us/step - loss: 0.5914 - accuracy: 0.7120\n",
      "Epoch 31/100\n",
      "803/803 [==============================] - 1s 832us/step - loss: 0.5854 - accuracy: 0.7129\n",
      "Epoch 32/100\n",
      "803/803 [==============================] - 1s 924us/step - loss: 0.5808 - accuracy: 0.7130\n",
      "Epoch 33/100\n",
      "803/803 [==============================] - 1s 802us/step - loss: 0.5772 - accuracy: 0.7121\n",
      "Epoch 34/100\n",
      "803/803 [==============================] - 1s 1ms/step - loss: 0.5741 - accuracy: 0.7151\n",
      "Epoch 35/100\n",
      "803/803 [==============================] - 1s 866us/step - loss: 0.5716 - accuracy: 0.7230\n",
      "Epoch 36/100\n",
      "803/803 [==============================] - 1s 822us/step - loss: 0.5693 - accuracy: 0.7229\n",
      "Epoch 37/100\n",
      "803/803 [==============================] - 1s 732us/step - loss: 0.5674 - accuracy: 0.7248\n",
      "Epoch 38/100\n",
      "803/803 [==============================] - 1s 750us/step - loss: 0.5662 - accuracy: 0.7251\n",
      "Epoch 39/100\n",
      "803/803 [==============================] - 1s 737us/step - loss: 0.5645 - accuracy: 0.7258\n",
      "Epoch 40/100\n",
      "803/803 [==============================] - 1s 825us/step - loss: 0.5632 - accuracy: 0.7256\n",
      "Epoch 41/100\n",
      "803/803 [==============================] - 1s 784us/step - loss: 0.5625 - accuracy: 0.7260\n",
      "Epoch 42/100\n",
      "803/803 [==============================] - 1s 738us/step - loss: 0.5619 - accuracy: 0.7261\n",
      "Epoch 43/100\n",
      "803/803 [==============================] - 1s 821us/step - loss: 0.5616 - accuracy: 0.7257\n",
      "Epoch 44/100\n",
      "803/803 [==============================] - 1s 749us/step - loss: 0.5608 - accuracy: 0.7261\n",
      "Epoch 45/100\n",
      "803/803 [==============================] - 1s 735us/step - loss: 0.5604 - accuracy: 0.7259\n",
      "Epoch 46/100\n",
      "803/803 [==============================] - 1s 775us/step - loss: 0.5599 - accuracy: 0.7267\n",
      "Epoch 47/100\n",
      "803/803 [==============================] - 1s 725us/step - loss: 0.5593 - accuracy: 0.7276\n",
      "Epoch 48/100\n",
      "803/803 [==============================] - 1s 785us/step - loss: 0.5589 - accuracy: 0.7266\n",
      "Epoch 49/100\n",
      "803/803 [==============================] - 1s 741us/step - loss: 0.5588 - accuracy: 0.7280\n",
      "Epoch 50/100\n",
      "803/803 [==============================] - 1s 749us/step - loss: 0.5584 - accuracy: 0.7285\n",
      "Epoch 51/100\n",
      "803/803 [==============================] - 1s 792us/step - loss: 0.5581 - accuracy: 0.7289\n",
      "Epoch 52/100\n",
      "803/803 [==============================] - 1s 805us/step - loss: 0.5577 - accuracy: 0.7294\n",
      "Epoch 53/100\n",
      "803/803 [==============================] - 1s 881us/step - loss: 0.5575 - accuracy: 0.7296\n",
      "Epoch 54/100\n",
      "803/803 [==============================] - 1s 846us/step - loss: 0.5567 - accuracy: 0.7296\n",
      "Epoch 55/100\n",
      "803/803 [==============================] - 1s 831us/step - loss: 0.5565 - accuracy: 0.7294\n",
      "Epoch 56/100\n",
      "803/803 [==============================] - 1s 833us/step - loss: 0.5564 - accuracy: 0.7293\n",
      "Epoch 57/100\n",
      "803/803 [==============================] - 1s 838us/step - loss: 0.5565 - accuracy: 0.7300\n",
      "Epoch 58/100\n",
      "803/803 [==============================] - 1s 847us/step - loss: 0.5561 - accuracy: 0.7296\n",
      "Epoch 59/100\n",
      "803/803 [==============================] - 1s 816us/step - loss: 0.5562 - accuracy: 0.7298\n",
      "Epoch 60/100\n",
      "803/803 [==============================] - 1s 832us/step - loss: 0.5560 - accuracy: 0.7299\n",
      "Epoch 61/100\n",
      "803/803 [==============================] - 1s 838us/step - loss: 0.5558 - accuracy: 0.7302\n",
      "Epoch 62/100\n",
      "803/803 [==============================] - 1s 864us/step - loss: 0.5557 - accuracy: 0.7299\n",
      "Epoch 63/100\n",
      "803/803 [==============================] - 1s 873us/step - loss: 0.5578 - accuracy: 0.7301\n",
      "Epoch 64/100\n",
      "803/803 [==============================] - 1s 845us/step - loss: 0.5551 - accuracy: 0.7301\n",
      "Epoch 65/100\n",
      "803/803 [==============================] - 1s 796us/step - loss: 0.5551 - accuracy: 0.7303\n",
      "Epoch 66/100\n",
      "803/803 [==============================] - 1s 833us/step - loss: 0.5547 - accuracy: 0.7304\n",
      "Epoch 67/100\n",
      "803/803 [==============================] - 1s 820us/step - loss: 0.5548 - accuracy: 0.7301\n",
      "Epoch 68/100\n",
      "803/803 [==============================] - 1s 811us/step - loss: 0.5549 - accuracy: 0.7305\n",
      "Epoch 69/100\n",
      "803/803 [==============================] - 1s 845us/step - loss: 0.5548 - accuracy: 0.7299\n",
      "Epoch 70/100\n",
      "803/803 [==============================] - 1s 879us/step - loss: 0.5547 - accuracy: 0.7304\n",
      "Epoch 71/100\n",
      "803/803 [==============================] - 1s 928us/step - loss: 0.5546 - accuracy: 0.7301\n",
      "Epoch 72/100\n",
      "803/803 [==============================] - 1s 868us/step - loss: 0.5543 - accuracy: 0.7304\n",
      "Epoch 73/100\n",
      "803/803 [==============================] - 1s 822us/step - loss: 0.5542 - accuracy: 0.7305\n",
      "Epoch 74/100\n",
      "803/803 [==============================] - 1s 821us/step - loss: 0.5542 - accuracy: 0.7304\n",
      "Epoch 75/100\n",
      "803/803 [==============================] - 1s 842us/step - loss: 0.5540 - accuracy: 0.7304\n",
      "Epoch 76/100\n",
      "803/803 [==============================] - 1s 820us/step - loss: 0.5540 - accuracy: 0.7305\n",
      "Epoch 77/100\n",
      "803/803 [==============================] - 1s 837us/step - loss: 0.5538 - accuracy: 0.7303\n",
      "Epoch 78/100\n",
      "803/803 [==============================] - 1s 914us/step - loss: 0.5538 - accuracy: 0.7306\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803/803 [==============================] - 1s 853us/step - loss: 0.5537 - accuracy: 0.7304\n",
      "Epoch 80/100\n",
      "803/803 [==============================] - 1s 785us/step - loss: 0.5537 - accuracy: 0.7301\n",
      "Epoch 81/100\n",
      "803/803 [==============================] - 1s 760us/step - loss: 0.5535 - accuracy: 0.7304\n",
      "Epoch 82/100\n",
      "803/803 [==============================] - 1s 784us/step - loss: 0.5535 - accuracy: 0.7305\n",
      "Epoch 83/100\n",
      "803/803 [==============================] - 1s 768us/step - loss: 0.5531 - accuracy: 0.7307\n",
      "Epoch 84/100\n",
      "803/803 [==============================] - 1s 822us/step - loss: 0.5532 - accuracy: 0.7303\n",
      "Epoch 85/100\n",
      "803/803 [==============================] - 1s 804us/step - loss: 0.5532 - accuracy: 0.7306\n",
      "Epoch 86/100\n",
      "803/803 [==============================] - 1s 768us/step - loss: 0.5546 - accuracy: 0.7306\n",
      "Epoch 87/100\n",
      "803/803 [==============================] - 1s 833us/step - loss: 0.5530 - accuracy: 0.7305\n",
      "Epoch 88/100\n",
      "803/803 [==============================] - 1s 789us/step - loss: 0.5530 - accuracy: 0.7303\n",
      "Epoch 89/100\n",
      "803/803 [==============================] - 1s 785us/step - loss: 0.5530 - accuracy: 0.7304\n",
      "Epoch 90/100\n",
      "803/803 [==============================] - 1s 780us/step - loss: 0.5528 - accuracy: 0.7304\n",
      "Epoch 91/100\n",
      "803/803 [==============================] - 1s 779us/step - loss: 0.5528 - accuracy: 0.7305\n",
      "Epoch 92/100\n",
      "803/803 [==============================] - 1s 750us/step - loss: 0.5528 - accuracy: 0.7307\n",
      "Epoch 93/100\n",
      "803/803 [==============================] - 1s 816us/step - loss: 0.5527 - accuracy: 0.7307\n",
      "Epoch 94/100\n",
      "803/803 [==============================] - 1s 774us/step - loss: 0.5526 - accuracy: 0.7307\n",
      "Epoch 95/100\n",
      "803/803 [==============================] - 1s 779us/step - loss: 0.5526 - accuracy: 0.7306\n",
      "Epoch 96/100\n",
      "803/803 [==============================] - 1s 773us/step - loss: 0.5524 - accuracy: 0.7305\n",
      "Epoch 97/100\n",
      "803/803 [==============================] - 1s 751us/step - loss: 0.5522 - accuracy: 0.7307\n",
      "Epoch 98/100\n",
      "803/803 [==============================] - 1s 874us/step - loss: 0.5524 - accuracy: 0.7306\n",
      "Epoch 99/100\n",
      "803/803 [==============================] - 1s 840us/step - loss: 0.5521 - accuracy: 0.7303\n",
      "Epoch 100/100\n",
      "803/803 [==============================] - 1s 938us/step - loss: 0.5523 - accuracy: 0.7305\n",
      "268/268 - 0s - loss: 0.5638 - accuracy: 0.7224\n",
      "Loss: 0.5637746453285217, Accuracy: 0.7223779559135437\n"
     ]
    }
   ],
   "source": [
    "# Define the model \n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 6\n",
    "hidden_nodes_layer2 = 4\n",
    "hidden_nodes_layer3 = 6\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Compile and train the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"Adamax\", metrics=[\"accuracy\"])\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparisons to other ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random forest predictive accuracy: 0.706\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest classifier, 64 estimators.\n",
    "rf_model = RandomForestClassifier(n_estimators=64, random_state=78)\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random forest predictive accuracy: 0.707\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest classifier, 128 estimators.\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=78)\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic regression model accuracy: 0.467\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model Accuracy\n",
    "log_classifier = LogisticRegression(solver=\"lbfgs\",max_iter=200)\n",
    "log_classifier.fit(X_train,y_train)\n",
    "y_pred = log_classifier.predict(X_test)\n",
    "print(f\" Logistic regression model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
